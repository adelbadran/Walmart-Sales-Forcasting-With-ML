# Walmart Sales Forecasting with Machine Learning

## ðŸ“Œ Description
Predicts Walmartâ€™s weekly sales using historical data, store info, and external factors â€” leveraging Linear Regression as a baseline and XGBoost as an advanced model for more accurate demand forecasting.

---

## ðŸ“‚ Dataset
This project uses the [Walmart Sales Forecast dataset by Aslan Ahmedov on Kaggle](https://www.kaggle.com/datasets/aslanahmedov/walmart-sales-forecast).  

Includes:
- Train data â†’ Weekly sales data by store and department from Feb 2010 to Nov 2012.  
- Test data â†’ Same format without Weekly_Sales values for prediction.  
- stores.csv â†’ Metadata for ~45 Walmart stores (type and size).  
- features.csv â†’ External variables like Temperature, Fuel_Price, CPI, Unemployment, and Holiday_Flag.  

This rich feature set enables modeling the effects of economic conditions and holidays on sales trends.

---

## Preprocessing Steps
1. Merge all datasets into one.
2. Handle missing values & duplicates.
3. Encode categorical features (`Type`, `IsHoliday`) into numeric format.
4. Create time-based features (`Year`, Month, Week, Day, Season, etc.).
5. Generate lag & rolling mean features for capturing trends.
6. Perform seasonal decomposition to understand patterns.
7. Remove outliers & apply scaling.

---

## ðŸ›  Tools & Libraries
- Python  
- Pandas, NumPy â†’ Data manipulation  
- Matplotlib, Seaborn â†’ Visualization  
- scikit-learn â†’ ML algorithms & metrics (Linear Regression)  
- XGBoost â†’ Gradient boosting regression  
- Statsmodels â†’ Time series decomposition  

---

## ðŸ“Š Methodology
1. Data Loading & Merging â†’ Combine Walmart sales, features, and store info.  
2. Cleaning â†’ Handle nulls, duplicates, and anomalies.  
3. Feature Engineering â†’ Temporal, lag, and statistical features.  
4. Model Training:
   - Linear Regression (baseline model)  
   - XGBoost (tuned with GridSearchCV)  
5. Evaluation:
   - Metrics â†’ SMAPE, RMSE, RÂ²  
6. Visualization â†’ Compare actual vs predicted weekly sales.  

---

## ðŸ“ˆ Results
| Model              | SMAPE (%) | RMSE   | RÂ²    |
|--------------------|-----------|--------|-------|
| Linear Regression  | 35.43     | 18.33  | 0.98  |
| XGBoost            | 28.31     | 13.16  | 0.99  |

- XGBoost significantly outperformed Linear Regression in accuracy and error reduction.  
- Seasonal trends and holiday effects were successfully captured.
