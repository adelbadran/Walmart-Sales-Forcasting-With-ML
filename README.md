# ğŸ›’ Walmart Sales Forecasting with Machine Learning

## ğŸ“Œ Description
Predicts Walmartâ€™s weekly sales using historical data, store info, and external factors, using Linear Regression as a baseline and XGBoost as an advanced model for more accurate demand forecasting.

---

## ğŸ“‚ Dataset
This project uses the [Walmart Sales Forecast dataset by Aslan Ahmedov on Kaggle](https://www.kaggle.com/datasets/aslanahmedov/walmart-sales-forecast).  

It includes:
- Train data: Weekly sales data by store and department from February 2010 to November 2012.
- Test data: Same format without Weekly_Sales values for prediction.
- stores.csv: Metadata for ~45 Walmart stores (type and size).
- features.csv: Contains external variables like Temperature, Fuel_Price, CPI, Unemployment, and Holiday_Flag.

This rich feature set enables modeling the effects of economic conditions and holidays on sales trends.

---

Preprocessing Steps:
1. Merge all datasets into one.
2. Handle missing values and duplicates.
3. Encode categorical features (`Type`, `IsHoliday`) into numeric format.
4. Create time-based features (Year, Month, Week, Day, Season, etc.).
5. Generate lag and rolling mean features for capturing trends.
6. Perform seasonal decomposition to understand patterns.
7. Remove outliers and apply scaling.

---

## ğŸ› ï¸ Tools & Libraries
- Python
- Pandas, NumPy â†’ Data manipulation
- Matplotlib, Seaborn â†’ Visualization
- scikit-learn â†’ ML algorithms & metrics (Linear Regression)
- XGBoost â†’ Gradient boosting regression
- Statsmodels â†’ Time series decomposition

---

## ğŸ“Š Methodology
1. Data Loading & Merging â†’ Combine Walmart sales, features, and store info.
2. Cleaning â†’ Handle nulls, duplicates, and remove anomalies.
3. Feature Engineering â†’ Create temporal, lag, and statistical features.
4. Model Training:
   - Linear Regression (baseline model)
   - XGBoost with hyperparameter tuning using GridSearchCV
5. Evaluation:
   - SMAPE, RMSE, RÂ²
6. Visualization â†’ Compare actual vs predicted weekly sales.

---

## ğŸ“ˆ Results (%)
| Model              | SMAPE | RMSE   | RÂ²    |
|--------------------|-----------|--------|-------|
| Linear Regression  | 35.43     | 18.33  | 0.98  |
| XGBoost            | 28.31     | 13.16  | 0.99  |

- XGBoost significantly outperformed Linear Regression in terms of accuracy and error reduction.
- Seasonal trends and holiday effects were successfully captured.
